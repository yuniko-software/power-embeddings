{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# E5 Large Instruct ONNX Conversion Research\n",
                "\n",
                "This notebook documents the conversion of the `intfloat/multilingual-e5-large-instruct` model to ONNX format, enabling cross-platform usage with identical results to the original HuggingFace implementation.\n",
                "\n",
                "## Key Features:\n",
                "1. Conversion of E5 Large Instruct model from HuggingFace to ONNX\n",
                "2. Conversion of tokenizer to ONNX using ONNX Extensions\n",
                "3. Implementation of average pooling and L2 normalization\n",
                "4. Verification of identical behavior between ONNX and HuggingFace implementations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install onnx onnxruntime onnxruntime-extensions numpy torch transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "import onnx\n",
                "import onnxruntime as ort\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from onnxruntime_extensions import gen_processing_models, get_library_path\n",
                "from transformers import AutoTokenizer, AutoModel\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. E5 Model Implementation and ONNX Wrapper"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "def average_pool(last_hidden_states, attention_mask):\n",
                "    \"\"\"Average pooling implementation matching the original\"\"\"\n",
                "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
                "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
                "\n",
                "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
                "    \"\"\"Format query with instruction as required by E5\"\"\"\n",
                "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
                "\n",
                "class E5LargeInstructONNXWrapper(nn.Module):\n",
                "    \"\"\"Wrapper class to make E5 Large Instruct compatible with ONNX export\"\"\"\n",
                "    def __init__(self, model):\n",
                "        super().__init__()\n",
                "        self.model = model\n",
                "        \n",
                "    def forward(self, input_ids, attention_mask):\n",
                "        # Get model outputs\n",
                "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        \n",
                "        # Apply average pooling\n",
                "        embeddings = average_pool(outputs.last_hidden_state, attention_mask)\n",
                "        \n",
                "        # Apply L2 normalization\n",
                "        normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
                "        \n",
                "        return normalized_embeddings"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Export E5 Large Instruct Model to ONNX"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_e5_large_instruct_model(model_name_or_path=\"intfloat/multilingual-e5-large-instruct\", output_path=\"e5_large_instruct_model.onnx\"):\n",
                "    \"\"\"Export E5 Large Instruct model to ONNX format\"\"\"\n",
                "    print(f\"Loading E5 Large Instruct model from {model_name_or_path}\")\n",
                "    \n",
                "    # Load the model\n",
                "    model = AutoModel.from_pretrained(model_name_or_path)\n",
                "    \n",
                "    # Wrap the model\n",
                "    onnx_model = E5LargeInstructONNXWrapper(model)\n",
                "    onnx_model.eval()\n",
                "    \n",
                "    # Create dummy input\n",
                "    dummy_input_ids = torch.randint(0, 1000, (1, 512), dtype=torch.long)\n",
                "    dummy_attention_mask = torch.ones(1, 512, dtype=torch.long)\n",
                "    \n",
                "    print(\"Exporting model to ONNX...\")\n",
                "    \n",
                "    # Export to ONNX\n",
                "    torch.onnx.export(\n",
                "        onnx_model,\n",
                "        (dummy_input_ids, dummy_attention_mask),\n",
                "        output_path,\n",
                "        input_names=['input_ids', 'attention_mask'],\n",
                "        output_names=['embeddings'],\n",
                "        dynamic_axes={\n",
                "            'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n",
                "            'attention_mask': {0: 'batch_size', 1: 'sequence_length'},\n",
                "            'embeddings': {0: 'batch_size'}\n",
                "        },\n",
                "        opset_version=20,\n",
                "        export_params=True\n",
                "    )\n",
                "    \n",
                "    print(f\"Model exported to: {output_path}\")\n",
                "    \n",
                "    # Load the exported model and save with external data format\n",
                "    print(\"Converting to external data format...\")\n",
                "    \n",
                "    model = onnx.load(output_path)\n",
                "    \n",
                "    # Get directory and filename parts\n",
                "    output_dir = os.path.dirname(output_path)\n",
                "    base_filename = os.path.basename(output_path)\n",
                "    data_filename = base_filename.replace('.onnx', '.onnx_data')\n",
                "    data_path = os.path.join(output_dir, data_filename)\n",
                "    \n",
                "    onnx.save_model(\n",
                "        model, \n",
                "        output_path,\n",
                "        save_as_external_data=True,\n",
                "        all_tensors_to_one_file=True,\n",
                "        location=data_filename\n",
                "    )\n",
                "    \n",
                "    print(f\"✅ Standard format export completed!\")\n",
                "    print(f\"   Model graph: {output_path}\")\n",
                "    print(f\"   Model data:  {data_path}\")\n",
                "    \n",
                "    return output_path, data_path"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Export E5 Tokenizer to ONNX"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_e5_tokenizer_to_onnx(model_name=\"intfloat/multilingual-e5-large-instruct\", tokenizer_path=\"onnx/e5_large_instruct_tokenizer.onnx\"):\n",
                "    \"\"\"Export the E5 tokenizer to ONNX format\"\"\"\n",
                "    print(f\"Loading tokenizer from {model_name}\")\n",
                "    hf_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "    \n",
                "    if not os.path.exists(tokenizer_path):\n",
                "        print(f\"Generating ONNX tokenizer at {tokenizer_path}\")\n",
                "        tokenizer_model = gen_processing_models(hf_tokenizer, pre_kwargs={}, post_kwargs={})[0]\n",
                "        \n",
                "        # Ensure directory exists\n",
                "        os.makedirs(os.path.dirname(tokenizer_path), exist_ok=True)\n",
                "        \n",
                "        with open(tokenizer_path, \"wb\") as f:\n",
                "            f.write(tokenizer_model.SerializeToString())\n",
                "        print(f\"✅ Tokenizer exported to {tokenizer_path}\")\n",
                "    else:\n",
                "        print(f\"Using existing tokenizer at {tokenizer_path}\")\n",
                "    \n",
                "    return hf_tokenizer, tokenizer_path"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ONNX E5 Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "def convert_tokenizer_outputs(tokens, token_indices):\n",
                "    \"\"\"Convert tokenizer outputs to model input format\"\"\"\n",
                "    # Pair tokens with their indices and sort by position\n",
                "    token_pairs = list(zip(token_indices, tokens))\n",
                "    token_pairs.sort()  # Sort by position (token_indices)\n",
                "    \n",
                "    # Get ordered tokens\n",
                "    ordered_tokens = [pair[1] for pair in token_pairs]\n",
                "    \n",
                "    # Create input_ids and attention_mask\n",
                "    input_ids = np.array([ordered_tokens], dtype=np.int64)\n",
                "    attention_mask = np.ones_like(input_ids, dtype=np.int64)\n",
                "    \n",
                "    return input_ids, attention_mask\n",
                "\n",
                "class OnnxE5LargeInstructEmbedder:\n",
                "    \"\"\"E5 Large Instruct embedder using ONNX tokenizer and model\"\"\"\n",
                "    \n",
                "    def __init__(self, tokenizer_path, model_path):\n",
                "        \"\"\"Initialize the embedder with ONNX tokenizer and model\"\"\"\n",
                "        # Initialize tokenizer session\n",
                "        sess_options = ort.SessionOptions()\n",
                "        sess_options.register_custom_ops_library(get_library_path())\n",
                "        self.tokenizer_session = ort.InferenceSession(\n",
                "            tokenizer_path,\n",
                "            sess_options=sess_options,\n",
                "            providers=['CPUExecutionProvider']\n",
                "        )\n",
                "        \n",
                "        # Initialize model session\n",
                "        self.model_session = ort.InferenceSession(\n",
                "            model_path,\n",
                "            providers=['CPUExecutionProvider']\n",
                "        )\n",
                "    \n",
                "    @staticmethod\n",
                "    def get_detailed_instruct(task_description: str, query: str) -> str:\n",
                "        \"\"\"Format query with instruction as required by E5\"\"\"\n",
                "        return f'Instruct: {task_description}\\nQuery: {query}'\n",
                "    \n",
                "    def encode(self, texts):\n",
                "        \"\"\"Generate embeddings for the input texts\"\"\"\n",
                "        if isinstance(texts, str):\n",
                "            texts = [texts]\n",
                "        \n",
                "        embeddings = []\n",
                "        \n",
                "        for text in texts:\n",
                "            # Tokenize the input\n",
                "            tokenizer_outputs = self.tokenizer_session.run(None, {\"inputs\": np.array([text])})\n",
                "            tokens, _, token_indices = tokenizer_outputs\n",
                "            \n",
                "            # Convert to model input format\n",
                "            input_ids, attention_mask = convert_tokenizer_outputs(tokens, token_indices)\n",
                "            \n",
                "            # Generate embeddings\n",
                "            model_outputs = self.model_session.run(None, {\n",
                "                \"input_ids\": input_ids,\n",
                "                \"attention_mask\": attention_mask\n",
                "            })\n",
                "            \n",
                "            # Extract normalized embeddings\n",
                "            embedding = model_outputs[0][0]  # Remove batch dimension\n",
                "            embeddings.append(embedding)\n",
                "        \n",
                "        return np.array(embeddings) if len(embeddings) > 1 else embeddings[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Export Models and Compare Implementations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create onnx directory if it doesn't exist\n",
                "onnx_dir = \"./onnx\"\n",
                "if not os.path.exists(onnx_dir):\n",
                "    os.makedirs(onnx_dir)\n",
                "\n",
                "# Export tokenizer\n",
                "tokenizer_path = os.path.join(onnx_dir, \"e5_large_instruct_tokenizer.onnx\")\n",
                "hf_tokenizer, tokenizer_path = export_e5_tokenizer_to_onnx(tokenizer_path=tokenizer_path)\n",
                "\n",
                "# Export model\n",
                "model_path = os.path.join(onnx_dir, \"e5_large_instruct_model.onnx\")\n",
                "data_path = os.path.join(onnx_dir, \"e5_large_instruct_model.onnx_data\")\n",
                "\n",
                "if not os.path.exists(model_path) or not os.path.exists(data_path):\n",
                "    model_path, data_path = export_e5_large_instruct_model(output_path=model_path)\n",
                "else:\n",
                "    print(f\"Using existing ONNX model at {model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing E5 Large Instruct embeddings...\n",
                        "\n",
                        "=== COMPARISON ===\n",
                        "Text 1: Similarity=1.0000002384, Max diff=0.0000002310\n",
                        "  First 5 values (HF):   [ 0.02018587  0.01120439 -0.04514243 -0.03949937  0.01756799]\n",
                        "  First 5 values (ONNX): [ 0.02018598  0.01120445 -0.04514245 -0.03949942  0.01756793]\n",
                        "Text 2: Similarity=1.0000000000, Max diff=0.0000002887\n",
                        "  First 5 values (HF):   [ 0.04857631  0.05938286  0.00398631 -0.02070856  0.02414943]\n",
                        "  First 5 values (ONNX): [ 0.04857632  0.05938292  0.00398623 -0.02070858  0.02414938]\n",
                        "Text 3: Similarity=1.0000000000, Max diff=0.0000002738\n",
                        "  First 5 values (HF):   [ 0.0326695   0.00413252 -0.05025513 -0.02161583  0.03252118]\n",
                        "  First 5 values (ONNX): [ 0.03266948  0.00413257 -0.05025515 -0.02161592  0.03252107]\n",
                        "Text 4: Similarity=1.0000000000, Max diff=0.0000004210\n",
                        "  First 5 values (HF):   [ 0.04768918  0.05657836  0.00922346 -0.0189132   0.01720553]\n",
                        "  First 5 values (ONNX): [ 0.04768923  0.05657855  0.00922368 -0.01891332  0.01720552]\n",
                        "\n",
                        "=== SIMILARITY SCORES ===\n",
                        "HuggingFace scores: [[91.92852020263672, 67.58028411865234], [70.38142395019531, 92.13304138183594]]\n",
                        "ONNX scores:        [[91.9285659790039, 67.58031463623047], [70.38143157958984, 92.13310241699219]]\n",
                        "Maximum score difference: 0.000061\n",
                        "\n",
                        "✅ CONCLUSION: The ONNX and HuggingFace outputs match very closely!\n"
                    ]
                }
            ],
            "source": [
                "def compare_e5_embeddings():\n",
                "    \"\"\"Compare embeddings from ONNX vs original HuggingFace implementation\"\"\"\n",
                "    print(\"Comparing E5 Large Instruct embeddings...\")\n",
                "    \n",
                "    # Test data from the original example\n",
                "    task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
                "    queries = [\n",
                "        'how much protein should a female eat',\n",
                "        '南瓜的家常做法'\n",
                "    ]\n",
                "    documents = [\n",
                "        \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
                "        \"1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法: 1、南瓜用刀薄薄的削去表面一层皮,用勺子刮去瓤 2、擦成细丝(没有擦菜板就用刀慢慢切成细丝) 3、锅烧热放油,入葱花煸出香味 4、入南瓜丝快速翻炒一分钟左右,放盐、一点白糖和鸡精调味出锅 2.香葱炒南瓜 原料:南瓜1只 调料:香葱、蒜末、橄榄油、盐 做法: 1、将南瓜去皮,切成片 2、油锅8成热后,将蒜末放入爆香 3、爆香后,将南瓜片放入,翻炒 4、在翻炒的同时,可以不时地往锅里加水,但不要太多 5、放入盐,炒匀 6、南瓜差不多软和绵了之后,就可以关火 7、撒入香葱,即可出锅\"\n",
                "    ]\n",
                "    \n",
                "    # Prepare input texts\n",
                "    instruct_queries = [get_detailed_instruct(task, query) for query in queries]\n",
                "    input_texts = instruct_queries + documents\n",
                "    \n",
                "    # Original HuggingFace implementation\n",
                "    tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large-instruct')\n",
                "    model = AutoModel.from_pretrained('intfloat/multilingual-e5-large-instruct')\n",
                "    \n",
                "    batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
                "    outputs = model(**batch_dict)\n",
                "    hf_embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
                "    hf_embeddings = F.normalize(hf_embeddings, p=2, dim=1)\n",
                "    \n",
                "    # ONNX implementation\n",
                "    onnx_embedder = OnnxE5LargeInstructEmbedder(\n",
                "        tokenizer_path=os.path.join(onnx_dir, \"e5_large_instruct_tokenizer.onnx\"),\n",
                "        model_path=os.path.join(onnx_dir, \"e5_large_instruct_model.onnx\")\n",
                "    )\n",
                "    \n",
                "    onnx_embeddings = onnx_embedder.encode(input_texts)\n",
                "    \n",
                "    # Compare embeddings\n",
                "    print(\"\\n=== COMPARISON ===\")\n",
                "    for i, _ in enumerate(input_texts):\n",
                "        hf_emb = hf_embeddings[i].detach().numpy()\n",
                "        onnx_emb = onnx_embeddings[i]\n",
                "        \n",
                "        similarity = np.dot(hf_emb, onnx_emb) / (np.linalg.norm(hf_emb) * np.linalg.norm(onnx_emb))\n",
                "        max_diff = np.abs(hf_emb - onnx_emb).max()\n",
                "        \n",
                "        print(f\"Text {i+1}: Similarity={similarity:.10f}, Max diff={max_diff:.10f}\")\n",
                "        print(f\"  First 5 values (HF):   {hf_emb[:5]}\")\n",
                "        print(f\"  First 5 values (ONNX): {onnx_emb[:5]}\")\n",
                "    \n",
                "    # Calculate similarity scores like in the original example\n",
                "    print(\"\\n=== SIMILARITY SCORES ===\")\n",
                "    hf_scores = (hf_embeddings[:2] @ hf_embeddings[2:].T) * 100\n",
                "    onnx_scores = (onnx_embeddings[:2] @ onnx_embeddings[2:].T) * 100\n",
                "    \n",
                "    print(f\"HuggingFace scores: {hf_scores.tolist()}\")\n",
                "    print(f\"ONNX scores:        {onnx_scores.tolist()}\")\n",
                "    \n",
                "    # Check if scores are close (FIX: Use .detach().numpy())\n",
                "    score_diff = np.abs(hf_scores.detach().numpy() - onnx_scores).max()\n",
                "    print(f\"Maximum score difference: {score_diff:.6f}\")\n",
                "    \n",
                "    if score_diff < 0.01:\n",
                "        print(\"\\n✅ CONCLUSION: The ONNX and HuggingFace outputs match very closely!\")\n",
                "    else:\n",
                "        print(\"\\n⚠️ CONCLUSION: There are some differences between the ONNX and HuggingFace outputs.\")\n",
                "\n",
                "compare_e5_embeddings()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusions\n",
                "\n",
                "Our research has successfully achieved:\n",
                "\n",
                "1. **Complete E5 Large Instruct Model Conversion**: Successfully converted the model from HuggingFace to ONNX format, including average pooling and L2 normalization.\n",
                "\n",
                "2. **Tokenizer Conversion**: Converted the tokenizer from HuggingFace to ONNX format using ONNX Extensions.\n",
                "\n",
                "3. **Instruction Formatting**: Maintained the instruction formatting requirement that makes E5 effective for retrieval tasks.\n",
                "\n",
                "4. **Identical Behavior**: The ONNX implementation produces essentially identical outputs to the original HuggingFace implementation.\n",
                "\n",
                "This conversion enables E5 Large Instruct to be used in cross-platform applications, particularly in C# and Java, while maintaining full functionality and accuracy."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
